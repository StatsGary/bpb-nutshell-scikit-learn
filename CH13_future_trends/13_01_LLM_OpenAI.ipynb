{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee98b2d",
   "metadata": {},
   "source": [
    "# Using `OpenAI`'s GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea033b",
   "metadata": {},
   "source": [
    "## Generate API key\n",
    "Go to: https://auth.openai.com/log-in and generate an accout and set up and API key.\n",
    "\n",
    "This can be found under:\n",
    "\n",
    "1. Dashboard \n",
    "2. API keys(https://platform.openai.com/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8730cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73cc5e",
   "metadata": {},
   "source": [
    "## Code generation with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa405f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Write a Python function that does a leet coding \n",
    "Recursive Binary Search.\n",
    "The function should take a sorted list of integers \n",
    "and a target integer as input, \n",
    "and return the index of the target integer in the \n",
    "list if it exists, or -1 if it does not.\n",
    "The function should be implemented using recursion.\n",
    "The function should be named `recursive_binary_search` \n",
    "and should have the following signature:\n",
    "\n",
    "```python   \n",
    "def recursive_binary_search(arr: list[int], \n",
    "                            target: int) -> int:\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd716aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that generates Python code \n",
    "based on the provided prompt.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3d4ba",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c28c2c",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a41aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e14bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ],\n",
    "    max_tokens = 2048,\n",
    "    temperature = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_code = response.choices[0].message.content\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61420f64",
   "metadata": {},
   "source": [
    "## Extract Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e61079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "raw_output = response.choices[0].message.content\n",
    "match = re.search(r\"```python\\s+(.*?)```\", \n",
    "                  raw_output, re.DOTALL)\n",
    "if match:\n",
    "    python_code = match.group(1).strip()\n",
    "    print(python_code)\n",
    "else:\n",
    "    print(\"No Python code block found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47e75b",
   "metadata": {},
   "source": [
    "## Display Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"```python\\n{python_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d6b21",
   "metadata": {},
   "source": [
    "## Execute Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "target = 5\n",
    "result = recursive_binary_search(sorted_list, target)\n",
    "print(f\"The TARGET specified: {target} is at INDEX: {result} due to Python's üêç zero-based indexing.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7536a",
   "metadata": {},
   "source": [
    "# Summarisation and Translation with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae703eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that summarises long text and \n",
    "produces a concise, but informative summary. Please explain your response in \n",
    "a way that is easy to understand for a general audience.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a343dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Machine ethics\n",
    "Main articles: Machine ethics and AI alignment\n",
    "Machine ethics (or machine morality) is the field of research concerned \n",
    "with designing Artificial Moral Agents (AMAs), \n",
    "robots or artificially intelligent computers that behave morally or as though moral.[4][5][6][7] \n",
    "To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, \n",
    "like the standard characterizations of agency, rational agency, moral agency,\n",
    " and artificial agency, which are related to the concept of AMAs.[8]\n",
    "There are discussions on creating tests to see if an AI is capable of making ethical decisions. \n",
    "Alan Winfield concludes that the Turing test is flawed and the requirement for an \n",
    "AI to pass the test is too low.[9] A proposed alternative test is one called the Ethical Turing Test, \n",
    "which would improve on the current test by having multiple judges decide if the \n",
    "AI's decision is ethical or unethical.[9] Neuromorphic AI could be one way to create morally capable robots, \n",
    "as it aims to process information similarly to humans, nonlinearly and with millions of \n",
    "interconnected artificial neurons.[10] Similarly, whole-brain emulation (scanning a brain and simulating it on digital hardware) \n",
    "could also in principle lead to human-like robots, thus capable of moral actions.[11] \n",
    "And large language models are capable of approximating human moral judgments.[12] Inevitably, \n",
    "this raises the question of the environment in which such robots would learn about the world and \n",
    "whose morality they would inherit ‚Äì or if they end up developing human 'weaknesses' as well: selfishness, \n",
    "pro-survival attitudes, inconsistency, scale insensitivity, etc.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28181407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(user_prompt, system_prompt, \n",
    "                        model=\"gpt-4o\", **kwargs):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        **kwargs\n",
    "    )\n",
    "    return response.choices[0].message.content, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2318b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, _ = get_openai_response(user_prompt=USER_PROMPT, \n",
    "                    system_prompt=SYSTEM_PROMPT, \n",
    "                    model=MODEL, \n",
    "                    max_tokens=2048, \n",
    "                    temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(USER_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715358d",
   "metadata": {},
   "source": [
    "## Translation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Your job is to translate the provided source text into German.\n",
    "Please ensure that the translation is accurate and maintains the original meaning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d56b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_resp, _ = get_openai_response(\n",
    "    user_prompt=response, \n",
    "    system_prompt=SYSTEM_PROMPT, \n",
    "    model=MODEL, \n",
    "    max_tokens=2048, \n",
    "    temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0eac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47a974",
   "metadata": {},
   "source": [
    "## Back translate with Google Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94242fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "async def translate_text(text_to_translate, \n",
    "                         dest='en', src='de', **kwargs):\n",
    "    \"\"\"Asynchronously translates text using Google Translate.\"\"\"\n",
    "    async with Translator() as translator:\n",
    "         \"\"\"Async context manager for the translator.\"\"\"\n",
    "         result = await translator.translate(text_to_translate, \n",
    "                                             dest=dest, \n",
    "                                             src=src, **kwargs)\n",
    "         return result\n",
    "google_translate_res = await translate_text(text_to_translate=translated_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translate_res.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-book-py-12-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
