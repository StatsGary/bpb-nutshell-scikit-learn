{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìû Customer Segmentation üíÅ‚Äç‚ôÄÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unsupervised.styler import style_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_ds = pd.read_csv('data/customer_data.csv')\n",
    "cs_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataframe(cs_ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised.missing_values import missing_values_summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_miss_df, _ = missing_values_summarizer(cs_ds)\n",
    "style_dataframe(prop_miss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unecessary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dataset = cs_ds.drop(['CustomerID'], \n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(cs_dataset, \n",
    "                                   test_size=0.3, \n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_enc = OneHotEncoder(drop='first', \n",
    "                            handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_enc.fit(X_train[['Gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = one_hot_enc.transform(X_train[['Gender']]).toarray()\n",
    "X_test_encoded = one_hot_enc.transform(X_test[['Gender']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc_df = pd.DataFrame(\n",
    "    X_train_encoded, \n",
    "    columns=one_hot_enc.get_feature_names_out(['Gender'])\n",
    "    )\n",
    "X_test_enc_df = pd.DataFrame(\n",
    "    X_test_encoded, \n",
    "    columns=one_hot_enc.get_feature_names_out(['Gender'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(\n",
    "    [X_train.drop(['Gender'], axis=1), \n",
    "     X_train_enc_df], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat(\n",
    "    [X_test.drop(['Gender'], axis=1), \n",
    "     X_test_enc_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_clustering_metrics(k_vals, \n",
    "                            sil_scores, \n",
    "                            davies_scores, \n",
    "                            cal_hab_scores,\n",
    "                            x_axis_lbl='Number of clusters (k)',\n",
    "                            figsize=(10,15)):\n",
    "    \n",
    "    _, axes = plt.subplots(3, 1, figsize=figsize)\n",
    "    axes[0].plot(k_vals, sil_scores, marker='o', color='blue')\n",
    "    axes[0].set_title('Silhouette Score vs. Number of Clusters (K-Means)')\n",
    "    axes[0].set_xlabel(x_axis_lbl)\n",
    "    axes[0].set_ylabel('Silhouette Score')\n",
    "    axes[0].grid(True)\n",
    "    axes[1].plot(k_vals, davies_scores, marker='o', color='red')\n",
    "    axes[1].set_title('Davies-Bouldin Index vs. Number of Clusters')\n",
    "    axes[1].set_xlabel('Number of clusters (K)')\n",
    "    axes[1].set_ylabel('Davies-Bouldin Index')\n",
    "    axes[1].grid(True)\n",
    "    axes[2].plot(k_vals, cal_hab_scores, marker='o', color='green')\n",
    "    axes[2].set_title('Calinski-Harabasz Score vs. Number of Clusters')\n",
    "    axes[2].set_xlabel('Number of clusters (K)')\n",
    "    axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "    axes[2].grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (silhouette_score, \n",
    "                             davies_bouldin_score, \n",
    "                             calinski_harabasz_score)\n",
    "\n",
    "def find_optimal_clusters(X, model, \n",
    "                          n_clusters=10,\n",
    "                          majority_vote=True,\n",
    "                          visualize=True):\n",
    "    if not hasattr(model, \"fit\"):\n",
    "        raise ValueError(\"Not a Sci-Kit Learn Model\")\n",
    "\n",
    "    k_vals = range(2, n_clusters)\n",
    "    sil_scores = []\n",
    "    davies_scores = []\n",
    "    cal_hab_scores = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        if hasattr(model, 'n_clusters'):\n",
    "            model.set_params(n_clusters=k)\n",
    "\n",
    "        model.fit(X)\n",
    "        labels = model.labels_ if hasattr(model, \"labels_\") else model.fit_predict(X)\n",
    "        sil_scores.append(silhouette_score(X, labels))\n",
    "        davies_scores.append(davies_bouldin_score(X, labels))\n",
    "        cal_hab_scores.append(calinski_harabasz_score(X, labels))\n",
    "\n",
    "    optim_k_silhouette = k_vals[np.argmax(sil_scores)]  \n",
    "    optim_k_davies_bouldin = k_vals[np.argmin(davies_scores)] \n",
    "    optim_k_cal_hab = k_vals[np.argmax(cal_hab_scores)]  \n",
    "\n",
    "    print(f'Optimal cluster based on Silhouette score is: {optim_k_silhouette}')\n",
    "    print(f'Optimal cluster based on Davies-Bouldin score is: {optim_k_davies_bouldin}')\n",
    "    print(f'Optimal cluster based on Calinski-Harabasz score is: {optim_k_cal_hab}')\n",
    "\n",
    "    optim_k_comb = None\n",
    "    if majority_vote:\n",
    "        optim_k_comb = max(set([optim_k_silhouette, \n",
    "                          optim_k_davies_bouldin, \n",
    "                          optim_k_cal_hab]), \n",
    "                          key=[optim_k_silhouette, \n",
    "                               optim_k_davies_bouldin, \n",
    "                               optim_k_cal_hab].count)\n",
    "        \n",
    "    if visualize:\n",
    "        plot_clustering_metrics(k_vals, sil_scores=sil_scores, \n",
    "                                davies_scores=davies_scores, \n",
    "                                cal_hab_scores=cal_hab_scores)\n",
    "        \n",
    "    \n",
    "    return (optim_k_comb, optim_k_silhouette, \n",
    "            optim_k_cal_hab, optim_k_davies_bouldin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, _, _, _ = find_optimal_clusters(X=X_train_scaled, \n",
    "                                          n_clusters=10, \n",
    "                                          model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use optimal clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_labels = model.fit_predict(X=X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Principal Components Analysis for Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised.scatter import plot_scatter\n",
    "plot_scatter(X=reduced_data, labels=kmeans_labels, title='PCA on KMeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate clusters using Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_labels = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clusters, _, _, _ = find_optimal_clusters(X=X_test_scaled, n_clusters=10, model=model)\n",
    "test_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Silhouettes for Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised.silhouette_plot import silhouette_plot\n",
    "silhouette_plot(X_train_scaled, kmeans_labels, clusters, \n",
    "                silh_colors=['red', 'black', 'navy'],\n",
    "                title='Training Silhouette Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_plot(X_test_scaled, labels=test_cluster_labels, \n",
    "                n_clusters=test_clusters,\n",
    "                silh_colors=['red', 'black', 'navy'],\n",
    "                title='Testing Silhouette Plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
