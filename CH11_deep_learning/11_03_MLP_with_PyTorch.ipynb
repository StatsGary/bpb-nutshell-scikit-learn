{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff058db",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron (Deep Learning) with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4766957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deep_learn.metrics import compute_metrics\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a08b2f",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a385c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_data = pd.read_csv('data/synthetic_income_data.csv', \n",
    "                       index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mlp_data.drop(columns=['income'])\n",
    "y = mlp_data['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49379d",
   "metadata": {},
   "source": [
    "## Prepare train and test set splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e93721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=RANDOM_SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=1/9, random_state=RANDOM_SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef24c2b",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b03bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68173b7e",
   "metadata": {},
   "source": [
    "## Set CUDA driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a05a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch currently working on: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e1e45",
   "metadata": {},
   "source": [
    "## Convert data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def to_tensor(data, reshape=False):\n",
    "    tensor = torch.tensor(data, dtype=torch.float32)\n",
    "    return tensor.view(-1, 1) if reshape else tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfdcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = to_tensor(X_train_scaled)\n",
    "y_train_torch = to_tensor(y_train.to_numpy(), reshape=True)\n",
    "X_test_torch  = to_tensor(X_test_scaled)\n",
    "y_test_torch  = to_tensor(y_test.to_numpy(), reshape=True)\n",
    "X_val_torch   = to_tensor(X_val_scaled)\n",
    "y_val_torch   = to_tensor(y_val.to_numpy(), reshape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846df89f",
   "metadata": {},
   "source": [
    "## Create a Tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97afdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "val_dataset = TensorDataset(X_val_torch, y_val_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf939c34",
   "metadata": {},
   "source": [
    "## Create a `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, \n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, \n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc7874",
   "metadata": {},
   "source": [
    "## Build MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size=1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - input_size: int, number of input features\n",
    "        - hidden_layers: list of int, number of neurons in each hidden layer\n",
    "        - output_size: int, number of output features (default: 1)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4a3e3",
   "metadata": {},
   "source": [
    "## Put model on device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size=X.shape[1], \n",
    "            hidden_layers=[64, 32], \n",
    "            output_size=1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade3196",
   "metadata": {},
   "source": [
    "## Create Optimizer for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "LEARN_RATE = 0.001\n",
    "optimizer = Adam(model.parameters(), \n",
    "                             lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af01a57",
   "metadata": {},
   "source": [
    "## Create Loss Function to Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    def forward(self, yhat, y):\n",
    "        return self.mse(yhat, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0af879",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c9fed",
   "metadata": {},
   "source": [
    "## Build Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "EPOCHS = 100\n",
    "patience = 2  \n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Training]\", leave=False)\n",
    "\n",
    "    for features_batch, targets_batch in train_loop:\n",
    "        features_batch = features_batch.to(device)\n",
    "        targets_batch = targets_batch.to(device)\n",
    "        predictions = model(features_batch)\n",
    "        loss = loss_fn(predictions, targets_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        train_loop.set_postfix(train_loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_features, val_targets in val_loader:\n",
    "            val_features = val_features.to(device)\n",
    "            val_targets = val_targets.to(device)\n",
    "\n",
    "            val_predictions = model(val_features)\n",
    "            val_loss = loss_fn(val_predictions, val_targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'models/best_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1} (no improvement in val loss for {patience} epochs)\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "def plot_training_history(train_losses: Optional[List[float]] = None,\n",
    "                          valid_losses: Optional[List[float]] = None,\n",
    "                          log_y_axis: bool = True,\n",
    "                          figsize: Tuple[int, int] = (10, 6),\n",
    "                          train_label: str = 'Train Loss',\n",
    "                          valid_label: str = 'Validation Loss',\n",
    "                          plot_x_label: str = 'Epoch',\n",
    "                          plot_y_label: str = 'Loss',\n",
    "                          plot_title: str = 'Training and Validation Loss Over Epochs',\n",
    "                          show_grid: bool = True, \n",
    "                          train_args: Optional[Dict] = None,\n",
    "                          valid_args: Optional[Dict] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot training and validation loss over epochs.\n",
    "\n",
    "    Parameters:\n",
    "    - train_losses: List of training loss values\n",
    "    - valid_losses: List of validation loss values\n",
    "    - log_y_axis: Whether to use log scale for the y-axis\n",
    "    - figsize: Tuple for the plot size (width, height)\n",
    "    - train_label: Label for the training loss line\n",
    "    - valid_label: Label for the validation loss line\n",
    "    - train_args: Optional dict of plot kwargs for training loss line\n",
    "    - valid_args: Optional dict of plot kwargs for validation loss line\n",
    "    \"\"\"\n",
    "    if train_losses is None and valid_losses is None:\n",
    "        raise ValueError(\"At least one of train_losses or valid_losses must be provided.\")\n",
    "\n",
    "    train_args = train_args or {}\n",
    "    valid_args = valid_args or {}\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if train_losses is not None:\n",
    "        plt.plot(train_losses, label=train_label, **train_args)\n",
    "    if valid_losses is not None:\n",
    "        plt.plot(valid_losses, label=valid_label, **valid_args)\n",
    "\n",
    "    plt.xlabel(plot_x_label)\n",
    "    plt.ylabel(plot_y_label)\n",
    "    plt.title(plot_title)\n",
    "    plt.legend()\n",
    "    if log_y_axis:\n",
    "        plt.yscale('log')\n",
    "    plt.grid(show_grid)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(\n",
    "    train_losses, val_losses, \n",
    "    log_y_axis=True, figsize=(10,6),\n",
    "    train_args=dict(color='black', \n",
    "                    linestyle='-', \n",
    "                    linewidth=2),\n",
    "    valid_args=dict(color='grey', \n",
    "                    linestyle='--', \n",
    "                    linewidth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291e8be",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49244d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size=X.shape[1], \n",
    "            hidden_layers=[64, 32], \n",
    "            output_size=1) \n",
    "model.load_state_dict(torch.load('models/best_model.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448925ed",
   "metadata": {},
   "source": [
    "## Evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_torch.to(device))\n",
    "    rmse = torch.sqrt(loss_fn(preds, y_test_torch.to(device)))\n",
    "    \n",
    "print(\"PyTorch MLP RMSE:\", rmse.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2e352",
   "metadata": {},
   "source": [
    "## Using Regression Diagnostic Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c737c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelviz.regression import regression_diagnostics_panel\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_diagnostics_panel(\n",
    "    y_test=y_test_torch.cpu().numpy().flatten(),\n",
    "    y_pred=preds.cpu().detach().numpy().flatten(),\n",
    "    qq_line_color='grey', qq_point_color='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-book-py-12-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
