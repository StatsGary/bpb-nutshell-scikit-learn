{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIuQG9UDKd8w"
   },
   "source": [
    "# Advanced NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BEFtRInvgaHW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "houses = np.array([\n",
    "    [3, 2000, 10],  # House 1: 3 Bedrooms, 2000 sq ft, 10 years old\n",
    "    [2, 1500, 20],  # House 2: 2 Bedrooms, 1500 sq ft, 20 years old\n",
    "    [4, 2500, 5],   # House 3: 4 Bedrooms, 2500 sq ft, 5 years old\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dafx1F_yKuK8"
   },
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76bOEb5yggm6",
    "outputId": "a1690a5f-011f-43fc-dccf-ac64ce8b3157"
   },
   "outputs": [],
   "source": [
    "# Broadcast a scalar to add 1 bedroom to each house\n",
    "updated_bedrooms = houses[:, 0] + 1  # Adding 1 to each bedroom\n",
    "print(\"Updated bedrooms after broadcasting:\\n\", updated_bedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGYc1AK-gphm",
    "outputId": "879cbdad-bb02-4c32-ebf0-3003e6437339"
   },
   "outputs": [],
   "source": [
    "# Subtract 5 years from the age of all houses\n",
    "updated_age = houses[:, 2] - 5\n",
    "print(\"Updated house ages after broadcasting:\\n\", updated_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06PUCSmkgsLi",
    "outputId": "59318f54-7b1f-49fe-bc55-82377c1795b4"
   },
   "outputs": [],
   "source": [
    "# Broadcasting with arrays: Adjust size by multiplying all sizes by a factor of 1.1\n",
    "adjusted_size = houses[:, 1] * 1.1\n",
    "print(\"Adjusted house sizes (sq ft) by 10% increase:\\n\", adjusted_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJqMQoknLVAr"
   },
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qe-SLFIUhSs3",
    "outputId": "9b61cffb-f5fc-4adc-80b7-911e2b5a9f68"
   },
   "outputs": [],
   "source": [
    "print(houses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muU9SsGcg9pm",
    "outputId": "37c7a99d-87b2-435b-c97a-e8dea38a89e5"
   },
   "outputs": [],
   "source": [
    "# Reshape the 3x3 array into a 1D array (flat array)\n",
    "reshaped_houses = houses.reshape(-1)\n",
    "print(\"Reshaped houses (flattened):\\n\", reshaped_houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nSct2WnMhOA3",
    "outputId": "1605cdf2-abe4-4133-b98b-868be0f0eee5"
   },
   "outputs": [],
   "source": [
    "# Reshape into a 1x9 array\n",
    "reshaped_houses_1x9 = houses.reshape(1, 9)\n",
    "print(\"Reshaped houses into 1x9:\\n\", reshaped_houses_1x9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKN37Pkrho_t"
   },
   "source": [
    "## Joining arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3TtBJBVhvh2",
    "outputId": "e3b5c36c-d93f-47c8-b23b-40cf1e1c82f1"
   },
   "outputs": [],
   "source": [
    "# Create another array for joining purposes\n",
    "more_houses = np.array([\n",
    "    [5, 3000, 15],  # House 4: 5 Bedrooms, 3000 sq ft, 15 years old\n",
    "])\n",
    "\n",
    "# Join along axis 0 (adding more rows)\n",
    "joined_houses = np.concatenate((houses, more_houses), axis=0)\n",
    "print(\"Joined houses (by rows):\\n\", joined_houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03kMLZv9iOqU",
    "outputId": "75da6d60-020f-4937-ef62-4a89f0cb8d2c"
   },
   "outputs": [],
   "source": [
    "# Join along axis 1 (adding columns)\n",
    "extra_data = np.array([[100000], [120000], [140000]])\n",
    "joined_columns = np.concatenate((houses, extra_data), axis=1)\n",
    "print(\"Joined houses with extra column (price):\\n\", joined_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0lp7kVaiYTR"
   },
   "source": [
    "## Stacking arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqjMkpcyiaMb",
    "outputId": "2f0f585e-f399-4d95-afe5-ad9d99b5a0bd"
   },
   "outputs": [],
   "source": [
    "# Stack arrays vertically (row-wise)\n",
    "stacked_houses_vertically = np.vstack((houses, more_houses))\n",
    "print(\"Vertically stacked houses:\\n\", stacked_houses_vertically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RrmXgwmict6",
    "outputId": "a3fa8681-0b09-498b-e1f2-e48b4cc6df9e"
   },
   "outputs": [],
   "source": [
    "# Stack arrays horizontally (column-wise)\n",
    "stacked_houses_horizontally = np.hstack((houses, extra_data))\n",
    "print(\"Horizontally stacked houses with extra column:\\n\", stacked_houses_horizontally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNNDYg3Vim2S"
   },
   "source": [
    "### Checking data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgBqIunKio4x",
    "outputId": "81256732-0949-44c7-f4b6-270585000875"
   },
   "outputs": [],
   "source": [
    "# Check the data type of the array\n",
    "data_type = houses.dtype\n",
    "print(\"Data type of the houses array:\", data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93T9gbmJT9jV"
   },
   "source": [
    "## Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm4T1s_MV8SO"
   },
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f9gCnIDGUAAM"
   },
   "outputs": [],
   "source": [
    "houses = np.array([\n",
    "    [3, 2000, 10],  # House 1: 3 Bedrooms, 2000 sq ft, 10 years old\n",
    "    [2, 1500, 20],  # House 2: 2 Bedrooms, 1500 sq ft, 20 years old\n",
    "    [4, 2500, 5],   # House 3: 4 Bedrooms, 2500 sq ft, 5 years old\n",
    "])\n",
    "\n",
    "# Define the learned weights for the model: [weight for Bedrooms, weight for Size, weight for Age]\n",
    "weights = np.array([50, 100, -20])\n",
    "\n",
    "# Bias term (intercept)\n",
    "bias = 30000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fe9V8GdUYqH",
    "outputId": "8d9468fe-c665-444a-8d5d-89a2157e8905"
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication to predict prices for all houses at once\n",
    "predicted_prices = np.dot(houses, weights) + bias\n",
    "print(\"Predicted prices:\", predicted_prices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jELc8DtyUt1f"
   },
   "source": [
    "### Normalisation calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4lKp3dzUxwl",
    "outputId": "2205e3c2-6a0d-4d01-8e15-d5c51b4adf02"
   },
   "outputs": [],
   "source": [
    "# Normalize features (feature scaling)\n",
    "house_norms = np.linalg.norm(houses, axis=1, keepdims=True)\n",
    "normalized_houses = houses / house_norms\n",
    "\n",
    "# Predict house prices using normalized features\n",
    "predicted_prices_normalized = np.dot(normalized_houses, weights) + bias\n",
    "print(\"Predicted prices (normalized):\", predicted_prices_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktux9xFoU_e_"
   },
   "source": [
    "### Single value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBFWl8mwVE2R",
    "outputId": "70629477-c22e-4aba-c3ad-5fdbe099d8c0"
   },
   "outputs": [],
   "source": [
    "# Perform SVD on the feature matrix\n",
    "U, S, Vt = np.linalg.svd(houses, full_matrices=False)\n",
    "print(\"U matrix:\", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIWfiKbjWeIM",
    "outputId": "93deb967-2006-4c1e-8dce-563a7a52d3da"
   },
   "outputs": [],
   "source": [
    "print(\"Singular values:\", S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pes_oL_OWfiJ",
    "outputId": "7ce39680-9e7c-4610-cd73-083b2b70e820"
   },
   "outputs": [],
   "source": [
    "print(\"V transpose matrix:\", Vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlN-bK8KVIuX"
   },
   "source": [
    "Here, $U$ represents the house feature data in an orthogonal space, $S$ contains the singular values, and $Vt$ captures the relationships between the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGzM-8wvWmjz"
   },
   "source": [
    "### Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KKh5pY-WoaZ",
    "outputId": "ad76af52-a44b-4d9b-ee31-a8d235d8ff1e"
   },
   "outputs": [],
   "source": [
    "# Compute covariance matrix of the features\n",
    "cov_matrix = np.cov(houses, rowvar=False)\n",
    "print(\"Covariance matrix:\\n\", cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq4UOmBddaSZ"
   },
   "source": [
    "Visualising the Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "4tFjV4h0ddC3",
    "outputId": "b673b9ad-5d73-4a41-ea0c-fdd35400c763"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the data array with features for multiple houses: [Bedrooms, Size (sq ft), Age (years)]\n",
    "houses = np.array([\n",
    "    [3, 2000, 10],  # House 1: 3 Bedrooms, 2000 sq ft, 10 years old\n",
    "    [2, 1500, 20],  # House 2: 2 Bedrooms, 1500 sq ft, 20 years old\n",
    "    [4, 2500, 5],   # House 3: 4 Bedrooms, 2500 sq ft, 5 years old\n",
    "])\n",
    "\n",
    "# Standardize the data (subtract the mean and divide by the standard deviation)\n",
    "houses_standardized = (houses - np.mean(houses, axis=0)) / np.std(houses, axis=0)\n",
    "\n",
    "# Compute covariance matrix of the standardized features\n",
    "cov_matrix_standardized = np.cov(houses_standardized, rowvar=False)\n",
    "\n",
    "# Define the feature names for the labels\n",
    "feature_names = ['Bedrooms', 'Size (sq ft)', 'Age (years)']\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Use seaborn to create a heatmap for the covariance matrix with labels\n",
    "sns.heatmap(cov_matrix_standardized, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "            square=True, cbar_kws={\"shrink\": .8},\n",
    "            xticklabels=feature_names, yticklabels=feature_names)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"Covariance Matrix Heatmap with Standardized Features\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Features\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGiDDS2-XcyR"
   },
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4vYOhGzXMEa",
    "outputId": "465c79c2-68ee-4079-8257-c6bd71a5ad02"
   },
   "outputs": [],
   "source": [
    "# Compute the Pearson correlation matrix\n",
    "corr_matrix = np.corrcoef(houses, rowvar=False)\n",
    "print(\"Pearson correlation matrix:\\n\", corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl--A6-GWvmC"
   },
   "source": [
    "Why apply this: The covariance matrix shows how features are linearly related. For example, you could check if there's a strong positive or negative relationship between Bedrooms and Size. If two features are highly correlated, one might be redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InZ4Djz9erwx"
   },
   "source": [
    "#### Visualising the Pearson's Correlation Coefficient Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "wRRi7HkFew9v",
    "outputId": "46580086-397b-4000-9659-c85fce935d91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_correlation_matrix(data, feature_names):\n",
    "    \"\"\"\n",
    "    Compute and plot the Pearson correlation matrix for the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array of shape (n_samples, n_features)\n",
    "    - feature_names: List of feature names corresponding to the columns in data\n",
    "\n",
    "    Returns:\n",
    "    - None (displays the heatmap of the Pearson correlation matrix)\n",
    "    \"\"\"\n",
    "    data_standardized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    corr_matrix = np.corrcoef(data_standardized, rowvar=False)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "                square=True, cbar_kws={\"shrink\": .8},\n",
    "                xticklabels=feature_names, yticklabels=feature_names)\n",
    "    plt.title(\"Pearson Correlation Matrix Heatmap\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names\n",
    "feature_names = ['Bedrooms', 'Size (sq ft)', 'Age (years)']\n",
    "\n",
    "# Call the function to plot the Pearson correlation matrix\n",
    "plot_correlation_matrix(houses, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wztLPaUaW2rI"
   },
   "source": [
    "### QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P18t3RnDW7Cb"
   },
   "source": [
    "You could apply QR decomposition to decompose the houses matrix into an orthogonal matrix Q and an upper triangular matrix R.\n",
    "\n",
    "Why apply this: QR decomposition is useful when solving systems of linear equations or when performing least-squares fitting (which is at the core of linear regression).\n",
    "\n",
    "How to apply: Decompose the houses matrix using QR decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okS2a0JLW_mr",
    "outputId": "efd5a968-8628-447f-86ae-733d77640ac8"
   },
   "outputs": [],
   "source": [
    "Q, R = np.linalg.qr(houses)\n",
    "print(\"Q matrix:\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eYanWvcXiBV",
    "outputId": "04865c46-3b07-4790-d92a-479af69a3720"
   },
   "outputs": [],
   "source": [
    "print(\"R matrix:\", R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFbLi9izX-ro"
   },
   "source": [
    "### Eigenvalues and Eigen vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buezsyiSYEjW"
   },
   "source": [
    "You could compute the eigenvalues and eigenvectors of the covariance matrix to analyze the principal components of the features.\n",
    "\n",
    "Why apply this: Eigenvalues and eigenvectors help in understanding the direction of maximum variance in the data, which is the foundation of Principal Component Analysis (PCA). This is useful for feature reduction.\n",
    "How to apply this: Compute the eigenvalues and eigenvectors of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPw_zi2jYIII",
    "outputId": "f003fc2f-52ec-4ed4-b26d-db301e3bc9d1"
   },
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "print(\"Eigenvalues:\", eigenvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIoxsOytYfsu",
    "outputId": "b2bc576b-4f3a-4684-a3a0-c9b131bf96a8"
   },
   "outputs": [],
   "source": [
    "print(\"Eigenvectors:\\n\", eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfvvExz-bauj"
   },
   "source": [
    "#### Visualising the Orthogonal matrix for Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "8Iw0A0iXY5rM",
    "outputId": "c0c15d68-0ef6-490a-9302-7c49ced6c893"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example covariance matrix (could be derived from your dataset)\n",
    "cov_matrix = np.array([[4, 2],\n",
    "                       [2, 3]])\n",
    "\n",
    "# Calculate the eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Plotting the eigenvectors\n",
    "origin = np.array([0, 0])  # Origin point (0,0)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the eigenvectors scaled by their corresponding eigenvalues\n",
    "for i in range(len(eigenvalues)):\n",
    "    eigenvector = eigenvectors[:, i]\n",
    "    ax.arrow(origin[0], origin[1], eigenvector[0] * eigenvalues[i], eigenvector[1] * eigenvalues[i],\n",
    "             head_width=0.2, head_length=0.3, fc=['r', 'b'][i], ec=['r', 'b'][i])\n",
    "\n",
    "# Set up the plot to have equal scaling\n",
    "ax.set_xlim([-5, 5])\n",
    "ax.set_ylim([-5, 5])\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.title(\"Eigenvalues and Eigenvectors (Orthogonal Directions)\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "scikit-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
